# -*- coding: utf-8 -*-
"""image_denoising.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fVryJJcgmPA-6YvL3BHyOETh2_fa6a7e
"""

import gdown

url = "https://drive.google.com/uc?id=1NKA9mvoTjrgx2lRkA7qIzOnV1NsQWx16"
!wget url
output = "combined.zip"
gdown.download(url, output, quiet=False)

!unzip /content/combined.zip

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import warnings
warnings.filterwarnings("ignore")

import os
import pathlib
from matplotlib import pyplot as plt
import seaborn as sns
import pickle
import pandas as pd
import numpy as np
import cv2
import skimage
from skimage.util import random_noise
import tensorflow as tf

from tqdm.notebook import tqdm
import random

def get_images_paths(root_dir_ssid):
    # Getting SSID dataset images
    root = pathlib.Path(root_dir_ssid)
    img_paths = list(root.rglob("*.PNG*"))
    img_paths_lst = [str(path) for path in img_paths]

    gt_lst = []
    noisy_lst= []
    for p in img_paths_lst:
        img_type = p.split("/")[-1].split('_')[-3]
        if img_type=="NOISY":
            noisy_lst.append(p)
        elif img_type=="GT":
            gt_lst.append(p)

    noisy_array = np.asarray(noisy_lst)
    gt_array = np.asarray(gt_lst)
    
    return noisy_array, gt_array

from sklearn.model_selection import train_test_split

noisy_array_paths, gt_array_paths = get_images_paths("/content/SIDD_Medium_Srgb/Data")

noisy_train_paths, noisy_test_paths, gt_train_paths, gt_test_paths = train_test_split(noisy_array_paths, gt_array_paths, test_size=0.20, random_state=42)

# Get gt_images in memory
def get_images_in_mem(images_paths):
    images_lst = []
    for img_path in tqdm(images_paths):
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, (256, 256))
        images_lst.append(img)
    return np.array(images_lst)

noisy_train_images = get_images_in_mem(noisy_train_paths)
noisy_test_images = get_images_in_mem(noisy_test_paths)

gt_train_images = get_images_in_mem(gt_train_paths)
gt_test_images = get_images_in_mem(gt_test_paths)

print(noisy_train_images.shape)
print(noisy_test_images.shape)

print(gt_train_images.shape)
print(gt_test_images.shape)

f, axarr = plt.subplots(1,2, figsize=(14,14))
axarr[0].imshow(noisy_train_images[5])
axarr[0].set_title("Noisy image")
axarr[1].imshow(gt_train_images[5])
axarr[1].title.set_text("Ground Truth image")

def _up_down_flip(image, label):
    image = tf.image.flip_up_down(image)
    label = tf.image.flip_up_down(label)
    return image, label

def _left_right_flip(image, label):
    image = tf.image.flip_left_right(image)
    label = tf.image.flip_left_right(label)
    return image, label

def _rotate(image, label):
    random_angle = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)
    image = tf.image.rot90(image, random_angle)
    label = tf.image.rot90(label, random_angle)
    return image, label

def _hue(image, label):
    rand_value = random.uniform(-1,1)
    image = tf.image.adjust_hue(image, rand_value)
    label = tf.image.adjust_hue(label, rand_value)
    return image, label

def _brightness(image, label):
    rand_value = random.uniform(-0.08,0.25)
    image = tf.image.adjust_brightness(image, rand_value)
    label = tf.image.adjust_brightness(label, rand_value)
    return image, label

def _saturation(image, label):
    rand_value = random.uniform(1, 5)
    image = tf.image.adjust_saturation(image, rand_value)
    label = tf.image.adjust_saturation(label, rand_value)
    return image, label

def _contrast(image, label):
    rand_value = random.uniform(1, 3)
    image = tf.image.adjust_contrast(image, rand_value)
    label = tf.image.adjust_contrast(label, rand_value)
    return image, label

# What does batch, repeat, and shuffle do with TensorFlow Dataset?
# https://stackoverflow.com/q/53514495/7697658
def tf_data_generator(X, y, batch_size=32, augmentations=None):
    dataset = tf.data.Dataset.from_tensor_slices((X, y)) # This is the main step for data generation
    dataset = dataset.shuffle(1000, reshuffle_each_iteration=True)

    if augmentations:
        for f in augmentations:
            if np.random.uniform(0,1)<0.5:
                dataset = dataset.map(f, num_parallel_calls=2)

    dataset = dataset.repeat()
    dataset = dataset.batch(batch_size=batch_size, drop_remainder=True)
    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)
    return dataset

BATCH_SIZE=4
augmentation_lst = [_up_down_flip, _left_right_flip, _rotate]
image_generator_train = tf_data_generator(X=noisy_train_images, y=gt_train_images, batch_size=BATCH_SIZE, augmentations=augmentation_lst)
image_generator_test = tf_data_generator(X=noisy_test_images, y=gt_test_images, batch_size=BATCH_SIZE)

# SANITY CHECK of the Dataset generator
for noisy, gt in image_generator_train.take(1):  # only take first element of dataset
    numpy_images = noisy.numpy()
    numpy_labels = gt.numpy()

f, axarr = plt.subplots(1,2, figsize=(14,14))
axarr[0].imshow(numpy_images[1])
axarr[0].set_title("X-data noisy image")
axarr[0].set_axis_off()

axarr[1].imshow(numpy_labels[1])
axarr[1].set_title("y-data ground truth image")
axarr[1].set_axis_off()

import tensorflow as tf
from tensorflow.keras import models, layers
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, Activation, Flatten, Dense, Input, Add
from tensorflow.keras import initializers, regularizers
from tensorflow.keras.optimizers import Adam

def create_model():
    tf.keras.backend.clear_session()

    input_0 = Input(shape=(256,256,3), name="input_layer")
    conv_layer_1 = Conv2D(filters=256, kernel_size=2, padding='same', name="conv_1", activation='relu')(input_0)
    conv_layer_2 = Conv2D(filters=256, kernel_size=2, padding='same', name="conv_2", activation='relu')(conv_layer_1)
    conv_layer_3 = Conv2D(filters=256, kernel_size=3, padding='same', name="conv_3", activation='relu')(conv_layer_2)
    conv_layer_4 = Conv2D(filters=256, kernel_size=3, padding='same', name="conv_4", activation='relu')(conv_layer_3)
    conv_layer_5 = Conv2D(filters=128, kernel_size=3, padding='same', name="conv_5", activation='relu')(conv_layer_4)
    conv_layer_6 = Conv2D(filters=128, kernel_size=3, padding='same', name="conv_6", activation='relu')(conv_layer_5)
    conv_layer_7 = Conv2D(filters=128, kernel_size=3, padding='same', name="conv_7", activation='relu')(conv_layer_6)
    conv_layer_8 = Conv2D(filters=128, kernel_size=3, padding='same', name="conv_8", activation='relu')(conv_layer_7)
    conv_layer_9 = Conv2D(filters=128, kernel_size=3, padding='same', name="conv_9", activation='relu')(conv_layer_8)
    conv_layer_10 = Conv2D(filters=64, kernel_size=3, padding='same', name="conv_10", activation='relu')(conv_layer_9)
    conv_layer_11 = Conv2D(filters=64, kernel_size=3, padding='same', name="conv_11", activation='relu')(conv_layer_10)
    conv_layer_12 = Conv2D(filters=64, kernel_size=3, padding='same', name="conv_12", activation='relu')(conv_layer_11)
    conv_layer_13 = Conv2D(filters=64, kernel_size=3, padding='same', name="conv_13", activation='relu')(conv_layer_12)
    conv_layer_14 = Conv2D(filters=64, kernel_size=3, padding='same', name="conv_14", activation='relu')(conv_layer_13)
    conv_layer_15 = Conv2D(filters=32, kernel_size=3, padding='same', name="conv_15", activation='relu')(conv_layer_14)


    deconv_layer_15 = Conv2DTranspose(filters=64, kernel_size=2, padding='same', name="deconv_15")(conv_layer_15) 
    deconv_layer_15 = Add(name="add_1")([conv_layer_14, deconv_layer_15])
    deconv_layer_14 = Conv2DTranspose(filters=64, kernel_size=2, padding='same', name="deconv_14")(deconv_layer_15) 
    deconv_layer_14 = Add(name="add_2")([conv_layer_13, deconv_layer_14])
    deconv_layer_13 = Conv2DTranspose(filters=64, kernel_size=2, padding='same', name="deconv_13")(deconv_layer_14) 
    deconv_layer_13 = Add(name="add_3")([conv_layer_12, deconv_layer_13])
    deconv_layer_12 = Conv2DTranspose(filters=64, kernel_size=2, padding='same', name="deconv_12")(deconv_layer_13) 
    deconv_layer_12 = Add(name="add_4")([conv_layer_11, deconv_layer_12])
    deconv_layer_11 = Conv2DTranspose(filters=64, kernel_size=2, padding='same', name="deconv_11")(deconv_layer_12) 
    deconv_layer_11 = Add(name="add_5")([conv_layer_10, deconv_layer_11])
    deconv_layer_10 = Conv2DTranspose(filters=128, kernel_size=2, padding='same', name="deconv_10")(deconv_layer_11) 
    deconv_layer_10 = Add(name="add_6")([conv_layer_9, deconv_layer_10])
    deconv_layer_9 = Conv2DTranspose(filters=128, kernel_size=2, padding='same', name="deconv_9")(deconv_layer_10) 
    deconv_layer_9 = Add(name="add_7")([conv_layer_8, deconv_layer_9])
    deconv_layer_8 = Conv2DTranspose(filters=128, kernel_size=2, padding='same', name="deconv_8")(deconv_layer_9) 
    deconv_layer_8 = Add(name="add_8")([conv_layer_7, deconv_layer_8])
    deconv_layer_7 = Conv2DTranspose(filters=128, kernel_size=2, padding='same', name="deconv_7")(deconv_layer_8) 
    deconv_layer_7 = Add(name="add_9")([conv_layer_6, deconv_layer_7])
    deconv_layer_6 = Conv2DTranspose(filters=128, kernel_size=2, padding='same', name="deconv_6")(deconv_layer_7) 
    deconv_layer_6 = Add(name="add_10")([conv_layer_5, deconv_layer_6])
    deconv_layer_5 = Conv2DTranspose(filters=256, kernel_size=2, padding='same', name="deconv_5")(deconv_layer_6)
    deconv_layer_5 = Add(name="add_11")([conv_layer_4, deconv_layer_5])
    deconv_layer_4 = Conv2DTranspose(filters=256, kernel_size=2, padding='same', name="deconv_4")(deconv_layer_5)
    deconv_layer_3 = Conv2DTranspose(filters=256, kernel_size=3, padding='same', name="deconv_3")(deconv_layer_4)
    deconv_layer_3 = Add(name="add_12")([conv_layer_2, deconv_layer_3])
    deconv_layer_2 = Conv2DTranspose(filters=128, kernel_size=3, padding='same', name="deconv_2")(deconv_layer_3)
    deconv_layer_1 = Conv2DTranspose(filters=3, kernel_size=3, padding='same', name="deconv_1")(deconv_layer_2)
    out = Add(name="add_13")([input_0, deconv_layer_1])

    model = Model(inputs=[input_0], outputs=[out])
    return model

model = create_model()

steps_per_epoch_train = len(noisy_train_images)
steps_per_epoch_validation = len(noisy_test_images)

best_models_path = "/content/models/"
callbacks_lst = [
    tf.keras.callbacks.ModelCheckpoint(filepath=best_models_path+"best_REDNet_blindnoise_256x256.h5", period=10, save_weights_only=False),
    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', min_lr=0.000009, min_delta=0.0001, factor=0.75, patience=3, verbose=1, mode='min'),
    tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, min_delta=0.0001, patience=10)
]

import matplotlib.pyplot as plt

plt.plot(list(range(1, 49)), train_loss, color='b', label='Training loss')
plt.plot(list(range(1,  49)), val_loss, color='r', label='Validation loss')
plt.xlabel('Number of epochs')
plt.ylabel('Mean square error')
plt.title('Loss vs No. of epochs')
plt.legend()
plt.savefig('/content/loss_vs_epochs.png')
plt.show()

model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=Adam(learning_rate=0.001))
model.fit(image_generator_train, 
          validation_data=image_generator_test,
                        steps_per_epoch=steps_per_epoch_train,
                        validation_steps=steps_per_epoch_validation,
                        epochs=200,
                        verbose=1,
                        callbacks=callbacks_lst)

best_models_path = "/content/models/"
model.save(best_models_path+"best_REDNet_blindnoise_256x256_1.h5")

# Inference
def inference_single_image(model, noisy_image):
    input_image = np.expand_dims(noisy_image, axis=0)
    predicted_image = model.predict(input_image)
    
    return predicted_image[0]

def inference_batch_images(model, noisy_images):
    predicted_image = model.predict(noisy_images, batch_size=4)
    return predicted_image

def visualize_predictions(model, X_test, y_test, n):
    random_numbers = random.choices(range(X_test.shape[0]), k=n)    # Get n random indices
    for i in random_numbers:
        noisy_image = X_test[i]
        gt_image = y_test[i]
        predicted_image = inference_single_image(model, X_test[i])
        predicted_image/=255

        f, axarr = plt.subplots(1,3, figsize=(21,21))
        axarr[0].imshow(noisy_image)
        axarr[0].set_title("Noisy image")
        axarr[0].set_axis_off()
        axarr[1].imshow(gt_image)
        axarr[1].set_title("Ground truth image")
        axarr[1].set_axis_off()
        axarr[2].imshow(predicted_image)
        axarr[2].set_title("Predicted image")
        axarr[2].set_axis_off()

best_models_path = "/content/models/"
model = tf.keras.models.load_model(best_models_path+'best_REDNet_blindnoise_256x256_1.h5')

visualize_predictions(model, noisy_test_images, gt_test_images, 10)

from skimage.metrics import peak_signal_noise_ratio

predicted_images = inference_batch_images(model, noisy_test_images)
psnr_original_mean = 0
psnr_prediction_mean = 0

for gt_img, noisy_img, predicted_img in zip(gt_test_images, noisy_test_images, predicted_images):
    psnr_original_mean += peak_signal_noise_ratio(gt_img, noisy_img)
    psnr_prediction_mean += peak_signal_noise_ratio(gt_img, predicted_img)

psnr_original_mean/=gt_test_images.shape[0]
psnr_prediction_mean/=gt_test_images.shape[0]
print("Original average gt-noisy PSNR ->", psnr_original_mean)
print("Predicted average gt-predicted PSNR ->", psnr_prediction_mean)

from skimage.metrics import structural_similarity as ssim

predicted_images = inference_batch_images(model, noisy_test_images)
ssim_original_mean = 0
ssim_prediction_mean = 0

for gt_img, noisy_img, predicted_img in zip(gt_test_images, noisy_test_images, predicted_images):
    ssim_original_mean += ssim(gt_img, noisy_img, multichannel=True, data_range=noisy_img.max() - noisy_img.min())
    ssim_prediction_mean += ssim(gt_img, predicted_img, multichannel=True, data_range=predicted_img.max() - predicted_img.min())

ssim_original_mean/=gt_test_images.shape[0]
ssim_prediction_mean/=gt_test_images.shape[0]
print("Original average gt-noisy SSIM ->", ssim_original_mean)
print("Predicted average gt-predicted SSIM ->", ssim_prediction_mean)

from prettytable import PrettyTable

pt = PrettyTable()
print("Note: Improvements shown are over original pairs")
pt.field_names = ["Model", "PSNR", "SSIM", "PSNR Improvement", "SSIM improvement"]

pt.add_row(["Original X-y pairs (No Model)","26.3779","0.6000", "-", "-"])
pt.add_row(["REDNet (Baseline)","30.5713","0.7932", "4.1934","0.1932"])
pt.add_row(["MWCNN (using Wavelets)","32.5220","0.8397","6.1441","0.2397"])
pt.add_row(["PRIDNet (using Attention)","33.3105","0.8534","6.9326","0.2534"])

print(pt)